{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nanopq\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.datasets import make_blobs\n",
    "import sys\n",
    "import faiss\n",
    "import cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D = 1000000, 256\n",
    "\n",
    "CLUSTERS_NUMBER = 10000  # число групп\n",
    "\n",
    "np.random.seed(0)\n",
    "centers = np.random.randint(-2000, 2000, size=(CLUSTERS_NUMBER, D))  # создает K центров D-размерности, расположенных случайно\n",
    "\n",
    "vectors, y = make_blobs(n_samples=N, n_features=D, centers=centers, random_state=0)\n",
    "vectors = vectors.astype(np.float32)\n",
    "\n",
    "vectors_base, train_y = vectors[:N-50000], y[:N-50000]\n",
    "queries, test_y = vectors[N-50000:], y[N-50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 950000/950000 [00:41<00:00, 23043.10it/s]\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "def generate_graph(vectors, k_nearest):\n",
    "    index = faiss.IndexFlatL2(vectors.shape[1])  # длина вектора\n",
    "    index.add(vectors.astype('float32'))\n",
    "    _, indices = index.search(vectors.astype('float32'), k_nearest)\n",
    "    G = nx.Graph()\n",
    "    for i in tqdm(range(len(vectors)), total=len(vectors)):\n",
    "        for index in indices[i]:\n",
    "            if index != i:\n",
    "                G.add_edge(i, index)\n",
    "    return G\n",
    "\n",
    "\n",
    "k = 35    # количество ближайших соседей для связывания вершин\n",
    "\n",
    "\n",
    "# генерируем граф\n",
    "G = generate_graph(vectors_base, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_nodes = np.array(list(G.nodes()))\n",
    "G_edges = {}\n",
    "for node in G_nodes:\n",
    "    G_edges[node] = list(G.edges(node))\n",
    "G_nodes = G_nodes.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq = nanopq.PQ(M=2, Ks=128, verbose=False)\n",
    "\n",
    "pq.fit(vectors_base)\n",
    "X_code = pq.encode(vectors_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_map = defaultdict(list)\n",
    "\n",
    "for i in range(len(X_code)):\n",
    "    indexes_map[(X_code[i][0], X_code[i][1])].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(query, query_mi, G_edges=G_edges, G_nodes=G_nodes, indexes_map=indexes_map, vectors=vectors_base):\n",
    "\n",
    "    query_mi_neighbours = indexes_map[(query_mi[0][0], query_mi[0][1])]\n",
    "    \n",
    "    if len(query_mi_neighbours) > 0:\n",
    "        best_node = query_mi_neighbours[0]\n",
    "        best_dist = np.linalg.norm(vectors[best_node] - query)\n",
    "        for best_candidate in query_mi_neighbours:\n",
    "            dist = np.linalg.norm(vectors[best_candidate] - query)\n",
    "            if dist < best_dist:\n",
    "                best_node = best_candidate\n",
    "                best_dist = dist\n",
    "    else:\n",
    "        best_node = np.random.choice(G.nodes())\n",
    "        best_dist = np.linalg.norm(vectors[best_node] - query)\n",
    "    #return best_dist, best_node\n",
    "    queue = []\n",
    "    queue.append(best_node)\n",
    "    was = set()\n",
    "    was.add(best_node)\n",
    "    while len(queue) > 0:\n",
    "        node = queue.pop(0)\n",
    "        for edge in G_edges[node]:\n",
    "            dst = edge[1]\n",
    "            if dst in was:\n",
    "                continue\n",
    "            was.add(dst)\n",
    "            dist = np.linalg.norm(vectors[dst] - query)\n",
    "            if dist < best_dist:\n",
    "                queue.append(dst)\n",
    "                best_node = dst\n",
    "                best_dist = dist\n",
    "    return best_dist, best_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "950000\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexHNSWFlat(D, 32)\n",
    "index.hnsw.efConstruction = 40\n",
    "\n",
    "index.train(vectors_base)\n",
    "print(index.ntotal)   # 0\n",
    "index.add(vectors_base)\n",
    "print(index.ntotal)   # 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from find_nearest import find_nearest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indexes_map = dict(indexes_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:06<00:00, 7418.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my time: 6.743005275726318\n",
      "hnsw time: 13.462644338607788\n",
      "[[16337]] [[3531]] [[30132]]\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dist_better_my = 0\n",
    "dist_better_hnsw = 0\n",
    "dist_equal = 0\n",
    "\n",
    "gt_good_my = 0\n",
    "gt_good_hnsw = 0\n",
    "gt_good_both = 0\n",
    "\n",
    "result_my = []\n",
    "result_hnsw = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "indexes_map = dict(indexes_map)\n",
    "\n",
    "for test_number in tqdm(range(len(queries))):\n",
    "    query = np.array([queries[test_number]])\n",
    "    query_mi = pq.encode(query).astype(np.int32)\n",
    "    d1, i1 = find_nearest(np.array(queries[test_number]), query_mi, G_edges, G_nodes, indexes_map, vectors_base)\n",
    "    result_my.append([d1, i1])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"my time:\", end-start)\n",
    "start = time.time()\n",
    "for test_number in range(len(queries)):\n",
    "    d2, i2 = index.search(np.array([queries[test_number]]), 1)\n",
    "    #d2 = np.linalg.norm(vectors_base[i2[0][0]] - queries[test_number])\n",
    "    result_hnsw.append([d2, i2[0][0]])\n",
    "end = time.time()\n",
    "print(\"hnsw time:\", end-start)\n",
    "\n",
    "for test_number in range(len(queries)):\n",
    "    d1, i1 = result_my[test_number][0], result_my[test_number][1]\n",
    "    \n",
    "    d2, i2 = result_hnsw[test_number][0], result_hnsw[test_number][1]\n",
    "\n",
    "    #gt_good_my += gt[test_number][0] == i1 and gt[test_number][0] != i2\n",
    "    #gt_good_hnsw += gt[test_number][0] != i1 and gt[test_number][0] == i2\n",
    "    #gt_good_both += gt[test_number][0] == i1 and gt[test_number][0] == i2\n",
    "    \n",
    "    dist_better_my += d1 < d2\n",
    "    dist_equal += d1 == d2\n",
    "    dist_better_hnsw += d1 > d2\n",
    "print(dist_better_my, dist_equal, dist_better_hnsw)\n",
    "print(gt_good_my, gt_good_both, gt_good_hnsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировка завершена\n",
      "Количество векторов в индексе: 950000\n"
     ]
    }
   ],
   "source": [
    "quantizer = faiss.IndexFlatL2(D)  # Векторный квантайзер, используемый для кластеризации\n",
    "index = faiss.IndexIVFFlat(quantizer, D, 10000, faiss.METRIC_L2)\n",
    "\n",
    "# Тренируем индекс на базе данных\n",
    "index.train(vectors_base)\n",
    "print(\"Тренировка завершена\")\n",
    "\n",
    "# Добавляем данные в индекс\n",
    "index.add(vectors_base)\n",
    "print(\"Количество векторов в индексе:\", index.ntotal)\n",
    "\n",
    "# Устанавливаем параметр поиска\n",
    "index.nprobe = 10  # Количество кластеров, которые будут проверяться при поиске\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:23<00:00, 2095.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my time: 23.865410804748535\n",
      "hnsw time: 41.26941967010498\n",
      "0 49999 1\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dist_better_my = 0\n",
    "dist_better_hnsw = 0\n",
    "dist_equal = 0\n",
    "\n",
    "gt_good_my = 0\n",
    "gt_good_hnsw = 0\n",
    "gt_good_both = 0\n",
    "\n",
    "result_my = []\n",
    "result_hnsw = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "indexes_map = dict(indexes_map)\n",
    "\n",
    "for test_number in tqdm(range(len(queries))):\n",
    "    query = np.array([queries[test_number]])\n",
    "    query_mi = pq.encode(query).astype(np.int32)\n",
    "    d1, i1 = find_nearest(np.array(queries[test_number]), query_mi, G_edges, G_nodes, indexes_map, vectors_base)\n",
    "    result_my.append([d1, i1])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"my time:\", end-start)\n",
    "start = time.time()\n",
    "for test_number in range(len(queries)):\n",
    "    d2, i2 = index.search(np.array([queries[test_number]]), 1)\n",
    "    d2 = np.linalg.norm(vectors_base[i2[0][0]] - queries[test_number])\n",
    "    result_hnsw.append([d2, i2[0][0]])\n",
    "end = time.time()\n",
    "print(\"hnsw time:\", end-start)\n",
    "\n",
    "for test_number in range(len(queries)):\n",
    "    d1, i1 = result_my[test_number][0], result_my[test_number][1]\n",
    "    \n",
    "    d2, i2 = result_hnsw[test_number][0], result_hnsw[test_number][1]\n",
    "\n",
    "    #gt_good_my += gt[test_number][0] == i1 and gt[test_number][0] != i2\n",
    "    #gt_good_hnsw += gt[test_number][0] != i1 and gt[test_number][0] == i2\n",
    "    #gt_good_both += gt[test_number][0] == i1 and gt[test_number][0] == i2\n",
    "    \n",
    "    dist_better_my += d1 < d2\n",
    "    dist_equal += d1 == d2\n",
    "    dist_better_hnsw += d1 > d2\n",
    "print(dist_better_my, dist_equal, dist_better_hnsw)\n",
    "print(gt_good_my, gt_good_both, gt_good_hnsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировка завершена\n",
      "Количество векторов в индексе: 950000\n"
     ]
    }
   ],
   "source": [
    "nlist = 100  # Количество центроидов для кластеризации\n",
    "m = 16  # Число подпространств для PQ\n",
    "bits = 8  # Число бит на подпространство (чаще всего 8 бит)\n",
    "\n",
    "# Создаем индекс IVFPQ\n",
    "quantizer = faiss.IndexFlatL2(D)  # Векторный квантайзер, используемый для кластеризации\n",
    "index = faiss.IndexIVFPQ(quantizer, D, nlist, m, bits)\n",
    "\n",
    "# Тренируем индекс на базе данных\n",
    "index.train(vectors_base)\n",
    "print(\"Тренировка завершена\")\n",
    "\n",
    "# Добавляем данные в индекс\n",
    "index.add(vectors_base)\n",
    "print(\"Количество векторов в индексе:\", index.ntotal)\n",
    "\n",
    "# Устанавливаем параметр поиска\n",
    "index.nprobe = 20  # Количество кластеров, которые будут проверяться при поиске\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:28<00:00, 1773.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my time: 28.19642925262451\n",
      "hnsw time: 65.74541878700256\n",
      "49485 515 0\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dist_better_my = 0\n",
    "dist_better_hnsw = 0\n",
    "dist_equal = 0\n",
    "\n",
    "gt_good_my = 0\n",
    "gt_good_hnsw = 0\n",
    "gt_good_both = 0\n",
    "\n",
    "result_my = []\n",
    "result_hnsw = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "indexes_map = dict(indexes_map)\n",
    "\n",
    "for test_number in tqdm(range(len(queries))):\n",
    "    query = np.array([queries[test_number]])\n",
    "    query_mi = pq.encode(query).astype(np.int32)\n",
    "    d1, i1 = find_nearest(np.array(queries[test_number]), query_mi, G_edges, G_nodes, indexes_map, vectors_base)\n",
    "    result_my.append([d1, i1])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"my time:\", end-start)\n",
    "start = time.time()\n",
    "for test_number in range(len(queries)):\n",
    "    d2, i2 = index.search(np.array([queries[test_number]]), 1)\n",
    "    d2 = np.linalg.norm(vectors_base[i2[0][0]] - queries[test_number])\n",
    "    result_hnsw.append([d2, i2[0][0]])\n",
    "end = time.time()\n",
    "print(\"hnsw time:\", end-start)\n",
    "\n",
    "for test_number in range(len(queries)):\n",
    "    d1, i1 = result_my[test_number][0], result_my[test_number][1]\n",
    "    \n",
    "    d2, i2 = result_hnsw[test_number][0], result_hnsw[test_number][1]\n",
    "\n",
    "    #gt_good_my += gt[test_number][0] == i1 and gt[test_number][0] != i2\n",
    "    #gt_good_hnsw += gt[test_number][0] != i1 and gt[test_number][0] == i2\n",
    "    #gt_good_both += gt[test_number][0] == i1 and gt[test_number][0] == i2\n",
    "    \n",
    "    dist_better_my += d1 < d2\n",
    "    dist_equal += d1 == d2\n",
    "    dist_better_hnsw += d1 > d2\n",
    "print(dist_better_my, dist_equal, dist_better_hnsw)\n",
    "print(gt_good_my, gt_good_both, gt_good_hnsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
