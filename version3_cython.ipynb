{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nanopq\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.datasets import make_blobs\n",
    "import sys\n",
    "import faiss\n",
    "import cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sift...done\n"
     ]
    }
   ],
   "source": [
    "N, D = 1000000, 128\n",
    "\n",
    "def ivecs_read(fname):\n",
    "    a = np.fromfile(fname, dtype='int32')\n",
    "    d = a[0]\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy()\n",
    "\n",
    "\n",
    "def fvecs_read(fname):\n",
    "    return ivecs_read(fname).view('float32')\n",
    "\n",
    "def load_sift():\n",
    "    print(\"Loading sift...\", end='', file=sys.stderr)\n",
    "    xb = fvecs_read(\"sift/sift_base.fvecs\")\n",
    "    xq = fvecs_read(\"sift/sift_query.fvecs\")\n",
    "    gt = ivecs_read(\"sift/sift_groundtruth.ivecs\")\n",
    "    print(\"done\", file=sys.stderr)\n",
    "\n",
    "    return xb, xq, gt\n",
    "\n",
    "def load_gist():\n",
    "    D = 960\n",
    "    print(\"Loading gist...\", end='', file=sys.stderr)\n",
    "    xb = fvecs_read(\"gist/gist_base.fvecs\")\n",
    "    xq = fvecs_read(\"gist/gist_query.fvecs\")\n",
    "    gt = ivecs_read(\"gist/gist_groundtruth.ivecs\")\n",
    "    print(\"done\", file=sys.stderr)\n",
    "\n",
    "    return xb, xq, gt\n",
    "\n",
    "\n",
    "vectors_base, queries, gt = load_sift()\n",
    "#vectors_base = vectors_base[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = 960\n",
    "len(vectors_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:46<00:00, 21538.93it/s]\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "def generate_graph(vectors, k_nearest):\n",
    "    index = faiss.IndexFlatL2(vectors.shape[1])  # длина вектора\n",
    "    index.add(vectors.astype('float32'))\n",
    "    _, indices = index.search(vectors.astype('float32'), k_nearest)\n",
    "    G = nx.Graph()\n",
    "    for i in tqdm(range(len(vectors)), total=len(vectors)):\n",
    "        for index in indices[i]:\n",
    "            if index != i:\n",
    "                G.add_edge(i, index)\n",
    "    return G\n",
    "\n",
    "\n",
    "k = 35    # количество ближайших соседей для связывания вершин\n",
    "\n",
    "\n",
    "# генерируем граф\n",
    "G = generate_graph(vectors_base, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_nodes = np.array(list(G.nodes()))\n",
    "G_edges = {}\n",
    "for node in G_nodes:\n",
    "    G_edges[node] = list(G.edges(node))\n",
    "G_nodes = G_nodes.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq = nanopq.PQ(M=2, Ks=128, verbose=False)\n",
    "\n",
    "pq.fit(vectors_base)\n",
    "X_code = pq.encode(vectors_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_map = defaultdict(list)\n",
    "\n",
    "for i in range(len(X_code)):\n",
    "    indexes_map[(X_code[i][0], X_code[i][1])].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(query, query_mi, G_edges=G_edges, G_nodes=G_nodes, indexes_map=indexes_map, vectors=vectors_base):\n",
    "\n",
    "    query_mi_neighbours = indexes_map.get((query_mi[0][0], query_mi[0][1]))\n",
    "    if query_mi_neighbours and len(query_mi_neighbours) > 0:\n",
    "        best_node = query_mi_neighbours[0]\n",
    "        best_dist = np.linalg.norm(vectors[best_node] - query)\n",
    "        for best_candidate in query_mi_neighbours:\n",
    "            dist = np.linalg.norm(vectors[best_candidate] - query)\n",
    "            if dist < best_dist:\n",
    "                best_node = best_candidate\n",
    "                best_dist = dist\n",
    "    else:\n",
    "        best_node = np.random.choice(G.nodes())\n",
    "        best_dist = np.linalg.norm(vectors[best_node] - query)\n",
    "    queue = []\n",
    "    queue.append(best_node)\n",
    "    was = set()\n",
    "    was.add(best_node)\n",
    "    while len(queue) > 0:\n",
    "        node = queue.pop(0)\n",
    "        for edge in G_edges[node]:\n",
    "            dst = edge[1]\n",
    "            if dst in was:\n",
    "                continue\n",
    "            was.add(dst)\n",
    "            dist = np.linalg.norm(vectors[dst] - query)\n",
    "            if dist < best_dist:\n",
    "                queue.append(dst)\n",
    "                best_node = dst\n",
    "                best_dist = dist\n",
    "    return best_dist, best_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from find_nearest import find_nearest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indexes_map = dict(indexes_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HNSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexHNSWFlat(D, 32)\n",
    "index.hnsw.efConstruction = 40\n",
    "\n",
    "index.train(vectors_base)\n",
    "print(index.ntotal)   # 0\n",
    "index.add(vectors_base)\n",
    "print(index.ntotal)   # 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2967.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my time: 3.3716166019439697\n",
      "hnsw time: 2.878054141998291\n",
      "0 0 10000\n",
      "285 6417 2659\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dist_better_my = 0\n",
    "dist_better_hnsw = 0\n",
    "dist_equal = 0\n",
    "\n",
    "gt_good_my = 0\n",
    "gt_good_hnsw = 0\n",
    "gt_good_both = 0\n",
    "\n",
    "result_my = []\n",
    "result_hnsw = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "indexes_map = dict(indexes_map)\n",
    "\n",
    "for test_number in tqdm(range(len(queries))):\n",
    "    query = np.array([queries[test_number]])\n",
    "    query_mi = pq.encode(query).astype(np.int32)\n",
    "    d1, i1 = find_nearest(np.array(queries[test_number]), query_mi, G_edges, G_nodes, indexes_map, vectors_base)\n",
    "    result_my.append([d1, i1])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"my time:\", end-start)\n",
    "start = time.time()\n",
    "for test_number in range(len(queries)):\n",
    "    d2, i2 = index.search(np.array([queries[test_number]]), 1)\n",
    "    d2 = np.linalg.norm(vectors_base[i2[0][0]] - queries[test_number])\n",
    "    result_hnsw.append([d2, i2[0][0]])\n",
    "end = time.time()\n",
    "print(\"hnsw time:\", end-start)\n",
    "\n",
    "for test_number in range(len(queries)):\n",
    "    d1, i1 = result_my[test_number][0], result_my[test_number][1]\n",
    "    \n",
    "    d2, i2 = result_hnsw[test_number][0], result_hnsw[test_number][1]\n",
    "\n",
    "    gt_good_my += gt[test_number][0] == i1 and gt[test_number][0] != i2\n",
    "    gt_good_hnsw += gt[test_number][0] != i1 and gt[test_number][0] == i2\n",
    "    gt_good_both += gt[test_number][0] == i1 and gt[test_number][0] == i2\n",
    "    \n",
    "    dist_better_my += d1 < d2\n",
    "    dist_equal += d1 == d2\n",
    "    dist_better_hnsw += d1 > d2\n",
    "print(dist_better_my, dist_equal, dist_better_hnsw)\n",
    "print(gt_good_my, gt_good_both, gt_good_hnsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировка завершена\n",
      "Количество векторов в индексе: 1000000\n"
     ]
    }
   ],
   "source": [
    "quantizer = faiss.IndexFlatL2(D)  # Векторный квантайзер, используемый для кластеризации\n",
    "index = faiss.IndexIVFFlat(quantizer, D, 10000, faiss.METRIC_L2)\n",
    "\n",
    "# Тренируем индекс на базе данных\n",
    "index.train(vectors_base)\n",
    "print(\"Тренировка завершена\")\n",
    "\n",
    "# Добавляем данные в индекс\n",
    "index.add(vectors_base)\n",
    "print(\"Количество векторов в индексе:\", index.ntotal)\n",
    "\n",
    "# Устанавливаем параметр поиска\n",
    "index.nprobe = 10  # Количество кластеров, которые будут проверяться при поиске\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2980.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my time: 3.355870246887207\n",
      "hnsw time: 1.157860279083252\n",
      "[[1342]] [[5966]] [[2692]]\n",
      "1099 5604 2093\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dist_better_my = 0\n",
    "dist_better_hnsw = 0\n",
    "dist_equal = 0\n",
    "\n",
    "gt_good_my = 0\n",
    "gt_good_hnsw = 0\n",
    "gt_good_both = 0\n",
    "\n",
    "result_my = []\n",
    "result_hnsw = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "indexes_map = dict(indexes_map)\n",
    "\n",
    "for test_number in tqdm(range(len(queries))):\n",
    "    query = np.array([queries[test_number]])\n",
    "    query_mi = pq.encode(query).astype(np.int32)\n",
    "    d1, i1 = find_nearest(np.array(queries[test_number]), query_mi, G_edges, G_nodes, indexes_map, vectors_base)\n",
    "    result_my.append([d1, i1])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"my time:\", end-start)\n",
    "start = time.time()\n",
    "for test_number in range(len(queries)):\n",
    "    d2, i2 = index.search(np.array([queries[test_number]]), 1)\n",
    "    #d2 = np.linalg.norm(vectors_base[i2[0][0]] - queries[test_number])\n",
    "    result_hnsw.append([d2, i2[0][0]])\n",
    "end = time.time()\n",
    "print(\"hnsw time:\", end-start)\n",
    "\n",
    "for test_number in range(len(queries)):\n",
    "    d1, i1 = result_my[test_number][0], result_my[test_number][1]\n",
    "    \n",
    "    d2, i2 = result_hnsw[test_number][0], result_hnsw[test_number][1]\n",
    "\n",
    "    gt_good_my += gt[test_number][0] == i1 and gt[test_number][0] != i2\n",
    "    gt_good_hnsw += gt[test_number][0] != i1 and gt[test_number][0] == i2\n",
    "    gt_good_both += gt[test_number][0] == i1 and gt[test_number][0] == i2\n",
    "    \n",
    "    dist_better_my += d1 < d2\n",
    "    dist_equal += d1 == d2\n",
    "    dist_better_hnsw += d1 > d2\n",
    "print(dist_better_my, dist_equal, dist_better_hnsw)\n",
    "print(gt_good_my, gt_good_both, gt_good_hnsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировка завершена\n",
      "Количество векторов в индексе: 1000000\n"
     ]
    }
   ],
   "source": [
    "nlist = 100  # Количество центроидов для кластеризации\n",
    "m = 16  # Число подпространств для PQ\n",
    "bits = 8  # Число бит на подпространство (чаще всего 8 бит)\n",
    "\n",
    "# Создаем индекс IVFPQ\n",
    "quantizer = faiss.IndexFlatL2(D)  # Векторный квантайзер, используемый для кластеризации\n",
    "index = faiss.IndexIVFPQ(quantizer, D, nlist, m, bits)\n",
    "\n",
    "# Тренируем индекс на базе данных\n",
    "index.train(vectors_base)\n",
    "print(\"Тренировка завершена\")\n",
    "\n",
    "# Добавляем данные в индекс\n",
    "index.add(vectors_base)\n",
    "print(\"Количество векторов в индексе:\", index.ntotal)\n",
    "\n",
    "# Устанавливаем параметр поиска\n",
    "index.nprobe = 10  # Количество кластеров, которые будут проверяться при поиске\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2915.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my time: 3.431389570236206\n",
      "hnsw time: 4.397719144821167\n",
      "[[5278]] [[0]] [[4722]]\n",
      "3421 3282 1179\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "dist_better_my = 0\n",
    "dist_better_hnsw = 0\n",
    "dist_equal = 0\n",
    "\n",
    "gt_good_my = 0\n",
    "gt_good_hnsw = 0\n",
    "gt_good_both = 0\n",
    "\n",
    "result_my = []\n",
    "result_hnsw = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "indexes_map = dict(indexes_map)\n",
    "\n",
    "for test_number in tqdm(range(len(queries))):\n",
    "    query = np.array([queries[test_number]])\n",
    "    query_mi = pq.encode(query).astype(np.int32)\n",
    "    d1, i1 = find_nearest(np.array(queries[test_number]), query_mi, G_edges, G_nodes, indexes_map, vectors_base)\n",
    "    result_my.append([d1, i1])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"my time:\", end-start)\n",
    "start = time.time()\n",
    "for test_number in range(len(queries)):\n",
    "    d2, i2 = index.search(np.array([queries[test_number]]), 1)\n",
    "    #d2 = np.linalg.norm(vectors_base[i2[0][0]] - queries[test_number])\n",
    "    result_hnsw.append([d2, i2[0][0]])\n",
    "end = time.time()\n",
    "print(\"hnsw time:\", end-start)\n",
    "\n",
    "for test_number in range(len(queries)):\n",
    "    d1, i1 = result_my[test_number][0], result_my[test_number][1]\n",
    "    \n",
    "    d2, i2 = result_hnsw[test_number][0], result_hnsw[test_number][1]\n",
    "\n",
    "    gt_good_my += gt[test_number][0] == i1 and gt[test_number][0] != i2\n",
    "    gt_good_hnsw += gt[test_number][0] != i1 and gt[test_number][0] == i2\n",
    "    gt_good_both += gt[test_number][0] == i1 and gt[test_number][0] == i2\n",
    "    \n",
    "    dist_better_my += d1 < d2\n",
    "    dist_equal += d1 == d2\n",
    "    dist_better_hnsw += d1 > d2\n",
    "print(dist_better_my, dist_equal, dist_better_hnsw)\n",
    "print(gt_good_my, gt_good_both, gt_good_hnsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
